{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rbfopt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obj_funct(x):\n",
    "  return x[0]*x[1] - x[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_decision_vars = 3\n",
    "lower_bound = np.array([0] * 3)\n",
    "upper_bound = np.array([10] * 3)\n",
    "decision_var_type = np.array(['R', 'I', 'R'])\n",
    "bb = rbfopt.RbfoptUserBlackBox(n_decision_vars, lower_bound, upper_bound, decision_var_type, obj_funct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These probably don't need to be set after a reboot since they should be in the command line path\n",
    "minlp_solver_path='C:/Apps/Bonmin/bonmin'\n",
    "nlp_solver_path='C:/Apps/IPOpt/ipopt'\n",
    "settings = rbfopt.RbfoptSettings(max_evaluations=50, minlp_solver_path = minlp_solver_path, nlp_solver_path = nlp_solver_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "alg = rbfopt.RbfoptAlgorithm(settings, bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Iter  Cycle  Action             Objective value      Time      Gap\n",
      "  ----  -----  ------             ---------------      ----      ---\n",
      "     0      0  Initialization           -0.782797      0.00   100.00 *\n",
      "     0      0  Initialization           69.095477      0.00   100.00  \n",
      "     0      0  Initialization           20.000000      0.01   100.00  \n",
      "     0      0  GlobalStep               -9.829600      0.02   100.00 *\n",
      "     1      0  GlobalStep               -9.946732      0.04   100.00 *\n",
      "     2      0  GlobalStep               -0.133622      0.06   100.00  \n",
      "     3      0  GlobalStep               -8.304083      0.08   100.00  \n",
      "     4      0  GlobalStep               -9.999968      0.09   100.00 *\n",
      "     5      0  LocalStep               -10.000000      0.17   100.00 *\n",
      "     6      1  GlobalStep               -4.524220      0.19   100.00  \n",
      "     7      1  GlobalStep               -4.921822      0.21   100.00  \n",
      "     8      1  GlobalStep               -9.056314      0.22   100.00  \n",
      "     9      1  GlobalStep               -9.873548      0.24   100.00  \n",
      "    10      1  GlobalStep               -9.987680      0.26   100.00  \n",
      "    11      1  LocalStep                -9.721112      0.33   100.00  \n",
      "    12      2  GlobalStep               -9.839303      0.36   100.00  \n",
      "    13      2  GlobalStep               -0.030919      0.37   100.00  \n",
      "    14      2  GlobalStep               -4.451368      0.39   100.00  \n",
      "    15      2  GlobalStep               -9.879600      0.41   100.00  \n",
      "    16      2  GlobalStep               -9.946653      0.42   100.00  \n",
      "    17      2  LocalStep               -10.000000      0.53   100.00  \n",
      "    18      2  RefinementStep           16.028501      0.53   100.00  \n",
      "    19      3  Discarded                               0.53\n",
      "    20      3  GlobalStep               -0.024032      0.57   100.00  \n",
      "    21      3  GlobalStep               -6.764801      0.58   100.00  \n",
      "    22      3  GlobalStep               -6.501387      0.60   100.00  \n",
      "    23      3  GlobalStep               -9.994080      0.62   100.00  \n",
      "    24      3  GlobalStep               -9.999701      0.64   100.00  \n",
      "    25      3  LocalStep               -10.000000      0.77   100.00  \n",
      "    26      4  GlobalStep               -0.269207      0.81   100.00  \n",
      "    27      4  GlobalStep               -5.629913      0.83   100.00  \n",
      "    28      4  GlobalStep               -7.213432      0.85   100.00  \n",
      "    29      4  GlobalStep               -9.976408      0.87   100.00  \n",
      "    30      4  GlobalStep               -9.998198      0.89   100.00  \n",
      "    31      4  LocalStep               -10.000000      1.04   100.00  \n",
      "    32      5  GlobalStep               -3.046904      1.10   100.00  \n",
      "    33      5  GlobalStep               -5.329923      1.11   100.00  \n",
      "    34      5  GlobalStep               -8.219087      1.13   100.00  \n",
      "    35      5  GlobalStep               -9.999337      1.15   100.00  \n",
      "    36      5  GlobalStep               -9.997845      1.17   100.00  \n",
      "    37      5  AdjLocalStep             -9.992657      1.36   100.00  \n",
      "    38      5  RefinementStep           -4.794300      1.36   100.00  \n",
      "    39      6  Discarded                               1.36\n",
      "    40      6  GlobalStep               -1.733273      1.43   100.00  \n",
      "    41      6  GlobalStep               -3.313290      1.45   100.00  \n",
      "    42      6  GlobalStep               -7.226346      1.47   100.00  \n",
      "    43      6  GlobalStep               -8.351180      1.49   100.00  \n",
      "    44      6  GlobalStep               -9.997359      1.51   100.00  \n",
      "    45      6  AdjLocalStep             -9.992170      5.34   100.00  \n",
      "    46      7  Discarded                               5.34\n",
      "    47      7  GlobalStep                5.963839      5.42   100.00  \n",
      "    48      7  GlobalStep               -2.697495      5.44   100.00  \n",
      "    49      7  GlobalStep               -9.634025      5.46   100.00  \n",
      "Summary: iters  50 evals  50 noisy_evals   0 cycles   7 opt_time    5.46 tot_time    5.46 obj       -10.000000 gap 100.00\n"
     ]
    }
   ],
   "source": [
    "val, x, itercount, evalcount, fast_evalcount = alg.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val:  -9.99999999999038\n",
      "x:  [ 5.20570019  0.         10.        ]\n",
      "x:  50\n",
      "evalcount:  50\n",
      "fast_evalcount:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"val: \", val)\n",
    "print(\"x: \", x)\n",
    "print(\"x: \", itercount)\n",
    "print(\"evalcount: \", evalcount)\n",
    "print(\"fast_evalcount: \", fast_evalcount)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
